{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "Reading classics [Deep Learning Models](https://github.com/rasbt/deeplearning-models)\n",
    "\n",
    "## Code Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np,pandas as pd,pylab as pl\n",
    "import h5py,torch,tensorflow as tf\n",
    "from torchvision.datasets import MNIST as tmnist\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader as tdl\n",
    "from torch.utils.data import Dataset as tds\n",
    "import torch.nn.functional as tnnf\n",
    "from IPython.core.magic import register_line_magic\n",
    "dev=torch.device(\"cuda:0\" \\\n",
    "if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": true,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class tdata(tds):\n",
    "    def __init__(self,X,y):   \n",
    "        self.X=torch.tensor(X,dtype=torch.float32)\n",
    "        self.y=torch.tensor(y,dtype=torch.int32)\n",
    "    def __getitem__(self,index):\n",
    "        image,label=self.X[index],self.y[index]\n",
    "        return image,label\n",
    "    def __len__(self):\n",
    "        return self.y.shape[0]\n",
    "def tloaders(x_train,y_train,x_test,y_test,batch_size):\n",
    "    train=tdata(x_train,y_train)\n",
    "    test=tdata(x_test,y_test)\n",
    "    train_loader=tdl(dataset=train,\n",
    "                     batch_size=batch_size,shuffle=True)\n",
    "    test_loader=tdl(dataset=test,\n",
    "                    batch_size=batch_size,shuffle=False)\n",
    "    return train_loader,test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 0s 0us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((60000, 28, 28, 1), (60000,))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(x_train,y_train),(x_test,y_test)=\\\n",
    "tf.keras.datasets.mnist.load_data()\n",
    "x_train=np.array(x_train,dtype='float32')/255\n",
    "x_train=x_train.reshape(-1,28,28,1)\n",
    "x_test=x_test.reshape(-1,28,28,1)\n",
    "x_test=np.array(x_test,dtype='float32')/255\n",
    "y_train=np.array(y_train,dtype='int32')\n",
    "y_test=np.array(y_test,dtype='int32')\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: torch.Size([64, 28, 28, 1])\n",
      "Label dimensions: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_loader,test_loader=\\\n",
    "tloaders(x_train,y_train,x_test,y_test,64)\n",
    "for images,labels in train_loader:  \n",
    "    print('Image dimensions: %s'%str(images.shape))\n",
    "    print('Label dimensions: %s'%str(labels.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['backgrounds', 'images', 'labels']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((11352, 32, 32, 3), (11352,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath='../input/classification-of-handwritten-letters/'\n",
    "f='LetterColorImages_123.h5'\n",
    "f=h5py.File(fpath+f,'r')\n",
    "keys=list(f.keys()); print(keys)\n",
    "x=np.array(f[keys[1]],dtype='float32')/255\n",
    "y=np.array(f[keys[2]],dtype='int32')-1\n",
    "N=len(y); n=int(.2*N)\n",
    "shuffle_ids=np.arange(N)\n",
    "np.random.RandomState(23).shuffle(shuffle_ids)\n",
    "x,y=x[shuffle_ids],y[shuffle_ids]\n",
    "x_test,x_train=x[:n],x[n:]\n",
    "y_test,y_train=y[:n],y[n:]\n",
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: torch.Size([64, 32, 32, 3])\n",
      "Label dimensions: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "train_loader2,test_loader2=\\\n",
    "tloaders(x_train,y_train,x_test,y_test,64)\n",
    "for images,labels in train_loader2:  \n",
    "    print('Image dimensions: %s'%str(images.shape))\n",
    "    print('Label dimensions: %s'%str(labels.shape))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## MLP with Sigmoid Activation & MSE Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPS():\n",
    "    def __init__(self,num_features,hidden,num_classes):\n",
    "        super(MLPS,self).__init__()\n",
    "        self.num_features=num_features\n",
    "        self.num_classes=num_classes\n",
    "        self.weight1=torch.zeros(hidden,num_features, \n",
    "                                 dtype=torch.float).normal_(0.,.1)\n",
    "        self.bias1=torch.zeros(hidden,dtype=torch.float)\n",
    "        self.weightout=torch.zeros(self.num_classes,hidden, \n",
    "                                   dtype=torch.float).normal_(0.,.1)\n",
    "        self.biasout=torch.zeros(self.num_classes,dtype=torch.float)        \n",
    "    def forward(self,x):\n",
    "        z1=torch.mm(x,self.weight1.t())+self.bias1\n",
    "        a1=torch.sigmoid(z1)\n",
    "        z2=torch.mm(a1,self.weightout.t())+self.biasout\n",
    "        a2=torch.sigmoid(z2)\n",
    "        return a1,a2\n",
    "    def backward(self,x,a1,a2,y):  \n",
    "        y_ohe=torch.FloatTensor(y.size(0),self.num_classes)\n",
    "        y_ohe.zero_()\n",
    "        y_ohe.scatter_(1,y.view(-1,1).long(),1)\n",
    "        dloss_da2=2.*(a2-y_ohe)/y.size(0)\n",
    "        da2_dz2=a2*(1.-a2)\n",
    "        delta_out=dloss_da2*da2_dz2\n",
    "        dz2__dw_out=a1\n",
    "        dloss__dw_out=torch.mm(delta_out.t(),dz2__dw_out)\n",
    "        dloss__db_out=torch.sum(delta_out,dim=0)\n",
    "        dz2__a1=self.weightout\n",
    "        dloss_a1=torch.mm(delta_out,dz2__a1)\n",
    "        da1__dz1=a1*(1.-a1)\n",
    "        dz1__dw1=x\n",
    "        dloss_dw1=torch.mm((dloss_a1*da1__dz1).t(),dz1__dw1)\n",
    "        dloss_db1=torch.sum((dloss_a1*da1__dz1),dim=0)\n",
    "        return dloss__dw_out,dloss__db_out,dloss_dw1,dloss_db1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def ohe(y,num_classes):\n",
    "    y_ohe=torch.FloatTensor(y.size(0),num_classes)\n",
    "    y_ohe.zero_()\n",
    "    y_ohe.scatter_(1,y.view(-1,1).long(),1).float()\n",
    "    return y_ohe\n",
    "def tloss(targets_ohe,probs_ohe):\n",
    "    return torch.mean(torch.mean((targets_ohe-probs_ohe)**2,dim=0))\n",
    "def tmse(model,data_loader):\n",
    "    curr_mse=torch.zeros(model.num_classes).float()\n",
    "    num_examples=0\n",
    "    with torch.no_grad():\n",
    "        for features,targets in data_loader:\n",
    "            features=features.view(-1,model.num_features)\n",
    "            logits,probs=model.forward(features)\n",
    "            y_ohe=ohe(targets,model.num_classes)\n",
    "            loss=torch.sum((y_ohe-probs)**2,dim=0)\n",
    "            num_examples+=targets.size(0)\n",
    "            curr_mse+=loss\n",
    "        curr_mse=torch.mean(curr_mse/num_examples,dim=0)\n",
    "        return curr_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_train(model,data_loader,num_epochs,learning_rate=.1):\n",
    "    minibatch_cost=[]; epoch_cost=[]  \n",
    "    for e in range(num_epochs):\n",
    "        for batch_idx,(features,targets) in enumerate(data_loader):            \n",
    "            features=features.view(-1,model.num_features)\n",
    "            a1,a2=model.forward(features)\n",
    "            dloss__dw_out,dloss__db_out,dloss_dw1,dloss_db1=\\\n",
    "            model.backward(features,a1,a2,targets)\n",
    "            model.weight1-=learning_rate*dloss_dw1\n",
    "            model.bias1-=learning_rate*dloss_db1\n",
    "            model.weightout-=learning_rate*dloss__dw_out\n",
    "            model.biasout-=learning_rate*dloss__db_out\n",
    "            curr_cost=tloss(ohe(targets,model.num_classes),a2)\n",
    "            minibatch_cost.append(curr_cost)\n",
    "            if not batch_idx%300:\n",
    "                print ('Epoch: %03d/%03d | Batch %03d/%03d | Cost: %.4f' \n",
    "                       %(e+1,num_epochs,batch_idx,\n",
    "                         len(data_loader),curr_cost))        \n",
    "        curr_cost=tmse(model,data_loader)\n",
    "        epoch_cost.append(curr_cost)\n",
    "        print('Epoch: %03d/%03d |'%(e+1,num_epochs),end=\" \")\n",
    "        print('Train MSE: %.5f'%curr_cost)\n",
    "    return minibatch_cost,epoch_cost\n",
    "def model_acc(model,data_loader):\n",
    "    correct_pred,num_examples=0,0\n",
    "    with torch.no_grad():\n",
    "        for features,targets in data_loader:\n",
    "            features=features.view(-1,model.num_features)\n",
    "            _,outputs=model.forward(features)\n",
    "            predicted_labels=torch.argmax(outputs,1)\n",
    "            num_examples+=targets.size(0)\n",
    "            correct_pred+=(predicted_labels==targets).sum()\n",
    "        return correct_pred.float()/num_examples*100 "
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/050 | Batch 000/938 | Cost: 0.2663\n",
      "Epoch: 001/050 | Batch 300/938 | Cost: 0.0718\n",
      "Epoch: 001/050 | Batch 600/938 | Cost: 0.0535\n",
      "Epoch: 001/050 | Batch 900/938 | Cost: 0.0558\n",
      "Epoch: 001/050 | Train MSE: 0.04497\n",
      "Epoch: 002/050 | Batch 000/938 | Cost: 0.0441\n",
      "Epoch: 002/050 | Batch 300/938 | Cost: 0.0367\n",
      "Epoch: 002/050 | Batch 600/938 | Cost: 0.0338\n",
      "Epoch: 002/050 | Batch 900/938 | Cost: 0.0355\n",
      "Epoch: 002/050 | Train MSE: 0.03112\n",
      "Epoch: 003/050 | Batch 000/938 | Cost: 0.0309\n",
      "Epoch: 003/050 | Batch 300/938 | Cost: 0.0328\n",
      "Epoch: 003/050 | Batch 600/938 | Cost: 0.0242\n",
      "Epoch: 003/050 | Batch 900/938 | Cost: 0.0308\n",
      "Epoch: 003/050 | Train MSE: 0.02578\n",
      "Epoch: 004/050 | Batch 000/938 | Cost: 0.0273\n",
      "Epoch: 004/050 | Batch 300/938 | Cost: 0.0205\n",
      "Epoch: 004/050 | Batch 600/938 | Cost: 0.0301\n",
      "Epoch: 004/050 | Batch 900/938 | Cost: 0.0309\n",
      "Epoch: 004/050 | Train MSE: 0.02291\n",
      "Epoch: 005/050 | Batch 000/938 | Cost: 0.0261\n",
      "Epoch: 005/050 | Batch 300/938 | Cost: 0.0200\n",
      "Epoch: 005/050 | Batch 600/938 | Cost: 0.0267\n",
      "Epoch: 005/050 | Batch 900/938 | Cost: 0.0205\n",
      "Epoch: 005/050 | Train MSE: 0.02111\n",
      "Epoch: 006/050 | Batch 000/938 | Cost: 0.0160\n",
      "Epoch: 006/050 | Batch 300/938 | Cost: 0.0242\n",
      "Epoch: 006/050 | Batch 600/938 | Cost: 0.0214\n",
      "Epoch: 006/050 | Batch 900/938 | Cost: 0.0131\n",
      "Epoch: 006/050 | Train MSE: 0.01975\n",
      "Epoch: 007/050 | Batch 000/938 | Cost: 0.0260\n",
      "Epoch: 007/050 | Batch 300/938 | Cost: 0.0199\n",
      "Epoch: 007/050 | Batch 600/938 | Cost: 0.0229\n",
      "Epoch: 007/050 | Batch 900/938 | Cost: 0.0208\n",
      "Epoch: 007/050 | Train MSE: 0.01884\n",
      "Epoch: 008/050 | Batch 000/938 | Cost: 0.0224\n",
      "Epoch: 008/050 | Batch 300/938 | Cost: 0.0130\n",
      "Epoch: 008/050 | Batch 600/938 | Cost: 0.0204\n",
      "Epoch: 008/050 | Batch 900/938 | Cost: 0.0176\n",
      "Epoch: 008/050 | Train MSE: 0.01793\n",
      "Epoch: 009/050 | Batch 000/938 | Cost: 0.0137\n",
      "Epoch: 009/050 | Batch 300/938 | Cost: 0.0167\n",
      "Epoch: 009/050 | Batch 600/938 | Cost: 0.0264\n",
      "Epoch: 009/050 | Batch 900/938 | Cost: 0.0123\n",
      "Epoch: 009/050 | Train MSE: 0.01723\n",
      "Epoch: 010/050 | Batch 000/938 | Cost: 0.0169\n",
      "Epoch: 010/050 | Batch 300/938 | Cost: 0.0128\n",
      "Epoch: 010/050 | Batch 600/938 | Cost: 0.0201\n",
      "Epoch: 010/050 | Batch 900/938 | Cost: 0.0095\n",
      "Epoch: 010/050 | Train MSE: 0.01664\n",
      "Epoch: 011/050 | Batch 000/938 | Cost: 0.0145\n",
      "Epoch: 011/050 | Batch 300/938 | Cost: 0.0159\n",
      "Epoch: 011/050 | Batch 600/938 | Cost: 0.0134\n",
      "Epoch: 011/050 | Batch 900/938 | Cost: 0.0176\n",
      "Epoch: 011/050 | Train MSE: 0.01612\n",
      "Epoch: 012/050 | Batch 000/938 | Cost: 0.0179\n",
      "Epoch: 012/050 | Batch 300/938 | Cost: 0.0178\n",
      "Epoch: 012/050 | Batch 600/938 | Cost: 0.0143\n",
      "Epoch: 012/050 | Batch 900/938 | Cost: 0.0152\n",
      "Epoch: 012/050 | Train MSE: 0.01565\n",
      "Epoch: 013/050 | Batch 000/938 | Cost: 0.0124\n",
      "Epoch: 013/050 | Batch 300/938 | Cost: 0.0088\n",
      "Epoch: 013/050 | Batch 600/938 | Cost: 0.0118\n",
      "Epoch: 013/050 | Batch 900/938 | Cost: 0.0112\n",
      "Epoch: 013/050 | Train MSE: 0.01521\n",
      "Epoch: 014/050 | Batch 000/938 | Cost: 0.0124\n",
      "Epoch: 014/050 | Batch 300/938 | Cost: 0.0141\n",
      "Epoch: 014/050 | Batch 600/938 | Cost: 0.0156\n",
      "Epoch: 014/050 | Batch 900/938 | Cost: 0.0178\n",
      "Epoch: 014/050 | Train MSE: 0.01484\n",
      "Epoch: 015/050 | Batch 000/938 | Cost: 0.0152\n",
      "Epoch: 015/050 | Batch 300/938 | Cost: 0.0115\n",
      "Epoch: 015/050 | Batch 600/938 | Cost: 0.0147\n",
      "Epoch: 015/050 | Batch 900/938 | Cost: 0.0151\n",
      "Epoch: 015/050 | Train MSE: 0.01449\n",
      "Epoch: 016/050 | Batch 000/938 | Cost: 0.0171\n",
      "Epoch: 016/050 | Batch 300/938 | Cost: 0.0093\n",
      "Epoch: 016/050 | Batch 600/938 | Cost: 0.0139\n",
      "Epoch: 016/050 | Batch 900/938 | Cost: 0.0195\n",
      "Epoch: 016/050 | Train MSE: 0.01413\n",
      "Epoch: 017/050 | Batch 000/938 | Cost: 0.0156\n",
      "Epoch: 017/050 | Batch 300/938 | Cost: 0.0167\n",
      "Epoch: 017/050 | Batch 600/938 | Cost: 0.0084\n",
      "Epoch: 017/050 | Batch 900/938 | Cost: 0.0094\n",
      "Epoch: 017/050 | Train MSE: 0.01383\n",
      "Epoch: 018/050 | Batch 000/938 | Cost: 0.0208\n",
      "Epoch: 018/050 | Batch 300/938 | Cost: 0.0106\n",
      "Epoch: 018/050 | Batch 600/938 | Cost: 0.0130\n",
      "Epoch: 018/050 | Batch 900/938 | Cost: 0.0112\n",
      "Epoch: 018/050 | Train MSE: 0.01354\n",
      "Epoch: 019/050 | Batch 000/938 | Cost: 0.0240\n",
      "Epoch: 019/050 | Batch 300/938 | Cost: 0.0161\n",
      "Epoch: 019/050 | Batch 600/938 | Cost: 0.0110\n",
      "Epoch: 019/050 | Batch 900/938 | Cost: 0.0146\n",
      "Epoch: 019/050 | Train MSE: 0.01328\n",
      "Epoch: 020/050 | Batch 000/938 | Cost: 0.0106\n",
      "Epoch: 020/050 | Batch 300/938 | Cost: 0.0180\n",
      "Epoch: 020/050 | Batch 600/938 | Cost: 0.0103\n",
      "Epoch: 020/050 | Batch 900/938 | Cost: 0.0095\n",
      "Epoch: 020/050 | Train MSE: 0.01310\n",
      "Epoch: 021/050 | Batch 000/938 | Cost: 0.0123\n",
      "Epoch: 021/050 | Batch 300/938 | Cost: 0.0117\n",
      "Epoch: 021/050 | Batch 600/938 | Cost: 0.0090\n",
      "Epoch: 021/050 | Batch 900/938 | Cost: 0.0084\n",
      "Epoch: 021/050 | Train MSE: 0.01281\n",
      "Epoch: 022/050 | Batch 000/938 | Cost: 0.0170\n",
      "Epoch: 022/050 | Batch 300/938 | Cost: 0.0104\n",
      "Epoch: 022/050 | Batch 600/938 | Cost: 0.0152\n",
      "Epoch: 022/050 | Batch 900/938 | Cost: 0.0169\n",
      "Epoch: 022/050 | Train MSE: 0.01258\n",
      "Epoch: 023/050 | Batch 000/938 | Cost: 0.0138\n",
      "Epoch: 023/050 | Batch 300/938 | Cost: 0.0109\n",
      "Epoch: 023/050 | Batch 600/938 | Cost: 0.0138\n",
      "Epoch: 023/050 | Batch 900/938 | Cost: 0.0102\n",
      "Epoch: 023/050 | Train MSE: 0.01236\n",
      "Epoch: 024/050 | Batch 000/938 | Cost: 0.0110\n",
      "Epoch: 024/050 | Batch 300/938 | Cost: 0.0117\n",
      "Epoch: 024/050 | Batch 600/938 | Cost: 0.0143\n",
      "Epoch: 024/050 | Batch 900/938 | Cost: 0.0080\n",
      "Epoch: 024/050 | Train MSE: 0.01216\n",
      "Epoch: 025/050 | Batch 000/938 | Cost: 0.0093\n",
      "Epoch: 025/050 | Batch 300/938 | Cost: 0.0082\n",
      "Epoch: 025/050 | Batch 600/938 | Cost: 0.0149\n",
      "Epoch: 025/050 | Batch 900/938 | Cost: 0.0059\n",
      "Epoch: 025/050 | Train MSE: 0.01196\n",
      "Epoch: 026/050 | Batch 000/938 | Cost: 0.0074\n",
      "Epoch: 026/050 | Batch 300/938 | Cost: 0.0130\n",
      "Epoch: 026/050 | Batch 600/938 | Cost: 0.0120\n",
      "Epoch: 026/050 | Batch 900/938 | Cost: 0.0098\n",
      "Epoch: 026/050 | Train MSE: 0.01177\n",
      "Epoch: 027/050 | Batch 000/938 | Cost: 0.0143\n",
      "Epoch: 027/050 | Batch 300/938 | Cost: 0.0125\n",
      "Epoch: 027/050 | Batch 600/938 | Cost: 0.0065\n",
      "Epoch: 027/050 | Batch 900/938 | Cost: 0.0103\n",
      "Epoch: 027/050 | Train MSE: 0.01160\n",
      "Epoch: 028/050 | Batch 000/938 | Cost: 0.0119\n",
      "Epoch: 028/050 | Batch 300/938 | Cost: 0.0133\n",
      "Epoch: 028/050 | Batch 600/938 | Cost: 0.0064\n",
      "Epoch: 028/050 | Batch 900/938 | Cost: 0.0120\n",
      "Epoch: 028/050 | Train MSE: 0.01143\n",
      "Epoch: 029/050 | Batch 000/938 | Cost: 0.0144\n",
      "Epoch: 029/050 | Batch 300/938 | Cost: 0.0157\n",
      "Epoch: 029/050 | Batch 600/938 | Cost: 0.0104\n",
      "Epoch: 029/050 | Batch 900/938 | Cost: 0.0148\n",
      "Epoch: 029/050 | Train MSE: 0.01126\n",
      "Epoch: 030/050 | Batch 000/938 | Cost: 0.0118\n",
      "Epoch: 030/050 | Batch 300/938 | Cost: 0.0098\n",
      "Epoch: 030/050 | Batch 600/938 | Cost: 0.0115\n",
      "Epoch: 030/050 | Batch 900/938 | Cost: 0.0150\n",
      "Epoch: 030/050 | Train MSE: 0.01110\n",
      "Epoch: 031/050 | Batch 000/938 | Cost: 0.0089\n",
      "Epoch: 031/050 | Batch 300/938 | Cost: 0.0149\n",
      "Epoch: 031/050 | Batch 600/938 | Cost: 0.0071\n",
      "Epoch: 031/050 | Batch 900/938 | Cost: 0.0103\n",
      "Epoch: 031/050 | Train MSE: 0.01094\n",
      "Epoch: 032/050 | Batch 000/938 | Cost: 0.0087\n",
      "Epoch: 032/050 | Batch 300/938 | Cost: 0.0121\n",
      "Epoch: 032/050 | Batch 600/938 | Cost: 0.0089\n",
      "Epoch: 032/050 | Batch 900/938 | Cost: 0.0119\n",
      "Epoch: 032/050 | Train MSE: 0.01080\n",
      "Epoch: 033/050 | Batch 000/938 | Cost: 0.0096\n",
      "Epoch: 033/050 | Batch 300/938 | Cost: 0.0101\n",
      "Epoch: 033/050 | Batch 600/938 | Cost: 0.0070\n",
      "Epoch: 033/050 | Batch 900/938 | Cost: 0.0069\n",
      "Epoch: 033/050 | Train MSE: 0.01066\n",
      "Epoch: 034/050 | Batch 000/938 | Cost: 0.0114\n",
      "Epoch: 034/050 | Batch 300/938 | Cost: 0.0095\n",
      "Epoch: 034/050 | Batch 600/938 | Cost: 0.0199\n",
      "Epoch: 034/050 | Batch 900/938 | Cost: 0.0109\n",
      "Epoch: 034/050 | Train MSE: 0.01053\n",
      "Epoch: 035/050 | Batch 000/938 | Cost: 0.0102\n",
      "Epoch: 035/050 | Batch 300/938 | Cost: 0.0143\n",
      "Epoch: 035/050 | Batch 600/938 | Cost: 0.0067\n",
      "Epoch: 035/050 | Batch 900/938 | Cost: 0.0055\n",
      "Epoch: 035/050 | Train MSE: 0.01039\n",
      "Epoch: 036/050 | Batch 000/938 | Cost: 0.0093\n",
      "Epoch: 036/050 | Batch 300/938 | Cost: 0.0073\n",
      "Epoch: 036/050 | Batch 600/938 | Cost: 0.0043\n",
      "Epoch: 036/050 | Batch 900/938 | Cost: 0.0120\n",
      "Epoch: 036/050 | Train MSE: 0.01025\n",
      "Epoch: 037/050 | Batch 000/938 | Cost: 0.0141\n",
      "Epoch: 037/050 | Batch 300/938 | Cost: 0.0073\n",
      "Epoch: 037/050 | Batch 600/938 | Cost: 0.0092\n",
      "Epoch: 037/050 | Batch 900/938 | Cost: 0.0037\n",
      "Epoch: 037/050 | Train MSE: 0.01013\n",
      "Epoch: 038/050 | Batch 000/938 | Cost: 0.0077\n",
      "Epoch: 038/050 | Batch 300/938 | Cost: 0.0122\n",
      "Epoch: 038/050 | Batch 600/938 | Cost: 0.0073\n",
      "Epoch: 038/050 | Batch 900/938 | Cost: 0.0139\n",
      "Epoch: 038/050 | Train MSE: 0.01002\n",
      "Epoch: 039/050 | Batch 000/938 | Cost: 0.0128\n",
      "Epoch: 039/050 | Batch 300/938 | Cost: 0.0113\n",
      "Epoch: 039/050 | Batch 600/938 | Cost: 0.0119\n",
      "Epoch: 039/050 | Batch 900/938 | Cost: 0.0078\n",
      "Epoch: 039/050 | Train MSE: 0.00987\n",
      "Epoch: 040/050 | Batch 000/938 | Cost: 0.0098\n",
      "Epoch: 040/050 | Batch 300/938 | Cost: 0.0092\n",
      "Epoch: 040/050 | Batch 600/938 | Cost: 0.0099\n",
      "Epoch: 040/050 | Batch 900/938 | Cost: 0.0101\n",
      "Epoch: 040/050 | Train MSE: 0.00977\n",
      "Epoch: 041/050 | Batch 000/938 | Cost: 0.0075\n",
      "Epoch: 041/050 | Batch 300/938 | Cost: 0.0097\n",
      "Epoch: 041/050 | Batch 600/938 | Cost: 0.0115\n",
      "Epoch: 041/050 | Batch 900/938 | Cost: 0.0076\n",
      "Epoch: 041/050 | Train MSE: 0.00965\n",
      "Epoch: 042/050 | Batch 000/938 | Cost: 0.0137\n",
      "Epoch: 042/050 | Batch 300/938 | Cost: 0.0082\n",
      "Epoch: 042/050 | Batch 600/938 | Cost: 0.0105\n",
      "Epoch: 042/050 | Batch 900/938 | Cost: 0.0034\n",
      "Epoch: 042/050 | Train MSE: 0.00953\n",
      "Epoch: 043/050 | Batch 000/938 | Cost: 0.0066\n",
      "Epoch: 043/050 | Batch 300/938 | Cost: 0.0083\n",
      "Epoch: 043/050 | Batch 600/938 | Cost: 0.0084\n",
      "Epoch: 043/050 | Batch 900/938 | Cost: 0.0070\n",
      "Epoch: 043/050 | Train MSE: 0.00945\n",
      "Epoch: 044/050 | Batch 000/938 | Cost: 0.0141\n",
      "Epoch: 044/050 | Batch 300/938 | Cost: 0.0113\n",
      "Epoch: 044/050 | Batch 600/938 | Cost: 0.0019\n",
      "Epoch: 044/050 | Batch 900/938 | Cost: 0.0092\n",
      "Epoch: 044/050 | Train MSE: 0.00934\n",
      "Epoch: 045/050 | Batch 000/938 | Cost: 0.0089\n",
      "Epoch: 045/050 | Batch 300/938 | Cost: 0.0107\n",
      "Epoch: 045/050 | Batch 600/938 | Cost: 0.0100\n",
      "Epoch: 045/050 | Batch 900/938 | Cost: 0.0084\n",
      "Epoch: 045/050 | Train MSE: 0.00921\n",
      "Epoch: 046/050 | Batch 000/938 | Cost: 0.0038\n",
      "Epoch: 046/050 | Batch 300/938 | Cost: 0.0089\n",
      "Epoch: 046/050 | Batch 600/938 | Cost: 0.0067\n",
      "Epoch: 046/050 | Batch 900/938 | Cost: 0.0072\n",
      "Epoch: 046/050 | Train MSE: 0.00911\n",
      "Epoch: 047/050 | Batch 000/938 | Cost: 0.0169\n",
      "Epoch: 047/050 | Batch 300/938 | Cost: 0.0055\n",
      "Epoch: 047/050 | Batch 600/938 | Cost: 0.0097\n",
      "Epoch: 047/050 | Batch 900/938 | Cost: 0.0067\n",
      "Epoch: 047/050 | Train MSE: 0.00902\n",
      "Epoch: 048/050 | Batch 000/938 | Cost: 0.0124\n",
      "Epoch: 048/050 | Batch 300/938 | Cost: 0.0102\n",
      "Epoch: 048/050 | Batch 600/938 | Cost: 0.0088\n",
      "Epoch: 048/050 | Batch 900/938 | Cost: 0.0059\n",
      "Epoch: 048/050 | Train MSE: 0.00893\n",
      "Epoch: 049/050 | Batch 000/938 | Cost: 0.0091\n",
      "Epoch: 049/050 | Batch 300/938 | Cost: 0.0100\n",
      "Epoch: 049/050 | Batch 600/938 | Cost: 0.0027\n",
      "Epoch: 049/050 | Batch 900/938 | Cost: 0.0094\n",
      "Epoch: 049/050 | Train MSE: 0.00882\n",
      "Epoch: 050/050 | Batch 000/938 | Cost: 0.0094\n",
      "Epoch: 050/050 | Batch 300/938 | Cost: 0.0076\n",
      "Epoch: 050/050 | Batch 600/938 | Cost: 0.0055\n",
      "Epoch: 050/050 | Batch 900/938 | Cost: 0.0071\n",
      "Epoch: 050/050 | Train MSE: 0.00877\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(23)\n",
    "model=MLPS(num_features=28*28*1,\n",
    "           hidden=128,num_classes=10)\n",
    "minibatch_cost,epoch_cost=\\\n",
    "model_train(model,train_loader,\n",
    "            num_epochs=50,learning_rate=.07)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 95.21\n",
      "Test Accuracy: 94.90\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy: %.2f'%model_acc(model,train_loader))\n",
    "print('Test Accuracy: %.2f'%model_acc(model,test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted labels:  tensor([1, 4, 9, 6, 9])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for features,targets in test_loader:\n",
    "    break\n",
    "fig,ax=pl.subplots(1,5)\n",
    "for i in range(5):\n",
    "    ax[i].imshow(features[5+i].view(28,28),\n",
    "                 cmap=pl.cm.bone)\n",
    "_,predictions=\\\n",
    "model.forward(features[5:10].view(-1,model.num_features))\n",
    "pred_labels=torch.argmax(predictions,dim=1)\n",
    "print('Predicted labels: ',pred_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": [
    "## Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-output": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001/200 | Batch 000/178 | Cost: 0.3685\n",
      "Epoch: 001/200 | Train MSE: 0.02970\n",
      "Epoch: 002/200 | Batch 000/178 | Cost: 0.0297\n",
      "Epoch: 002/200 | Train MSE: 0.02958\n",
      "Epoch: 003/200 | Batch 000/178 | Cost: 0.0297\n",
      "Epoch: 003/200 | Train MSE: 0.02950\n",
      "Epoch: 004/200 | Batch 000/178 | Cost: 0.0294\n",
      "Epoch: 004/200 | Train MSE: 0.02943\n",
      "Epoch: 005/200 | Batch 000/178 | Cost: 0.0294\n",
      "Epoch: 005/200 | Train MSE: 0.02937\n",
      "Epoch: 006/200 | Batch 000/178 | Cost: 0.0295\n",
      "Epoch: 006/200 | Train MSE: 0.02932\n",
      "Epoch: 007/200 | Batch 000/178 | Cost: 0.0294\n",
      "Epoch: 007/200 | Train MSE: 0.02929\n",
      "Epoch: 008/200 | Batch 000/178 | Cost: 0.0294\n",
      "Epoch: 008/200 | Train MSE: 0.02927\n",
      "Epoch: 009/200 | Batch 000/178 | Cost: 0.0293\n",
      "Epoch: 009/200 | Train MSE: 0.02925\n",
      "Epoch: 010/200 | Batch 000/178 | Cost: 0.0293\n",
      "Epoch: 010/200 | Train MSE: 0.02923\n",
      "Epoch: 011/200 | Batch 000/178 | Cost: 0.0294\n",
      "Epoch: 011/200 | Train MSE: 0.02923\n",
      "Epoch: 012/200 | Batch 000/178 | Cost: 0.0292\n",
      "Epoch: 012/200 | Train MSE: 0.02920\n",
      "Epoch: 013/200 | Batch 000/178 | Cost: 0.0292\n",
      "Epoch: 013/200 | Train MSE: 0.02919\n",
      "Epoch: 014/200 | Batch 000/178 | Cost: 0.0292\n",
      "Epoch: 014/200 | Train MSE: 0.02917\n",
      "Epoch: 015/200 | Batch 000/178 | Cost: 0.0290\n",
      "Epoch: 015/200 | Train MSE: 0.02915\n",
      "Epoch: 016/200 | Batch 000/178 | Cost: 0.0292\n",
      "Epoch: 016/200 | Train MSE: 0.02915\n",
      "Epoch: 017/200 | Batch 000/178 | Cost: 0.0292\n",
      "Epoch: 017/200 | Train MSE: 0.02913\n",
      "Epoch: 018/200 | Batch 000/178 | Cost: 0.0291\n",
      "Epoch: 018/200 | Train MSE: 0.02911\n",
      "Epoch: 019/200 | Batch 000/178 | Cost: 0.0291\n",
      "Epoch: 019/200 | Train MSE: 0.02909\n",
      "Epoch: 020/200 | Batch 000/178 | Cost: 0.0291\n",
      "Epoch: 020/200 | Train MSE: 0.02907\n",
      "Epoch: 021/200 | Batch 000/178 | Cost: 0.0292\n",
      "Epoch: 021/200 | Train MSE: 0.02905\n",
      "Epoch: 022/200 | Batch 000/178 | Cost: 0.0290\n",
      "Epoch: 022/200 | Train MSE: 0.02904\n",
      "Epoch: 023/200 | Batch 000/178 | Cost: 0.0292\n",
      "Epoch: 023/200 | Train MSE: 0.02902\n",
      "Epoch: 024/200 | Batch 000/178 | Cost: 0.0291\n",
      "Epoch: 024/200 | Train MSE: 0.02900\n",
      "Epoch: 025/200 | Batch 000/178 | Cost: 0.0288\n",
      "Epoch: 025/200 | Train MSE: 0.02901\n",
      "Epoch: 026/200 | Batch 000/178 | Cost: 0.0292\n",
      "Epoch: 026/200 | Train MSE: 0.02896\n",
      "Epoch: 027/200 | Batch 000/178 | Cost: 0.0289\n",
      "Epoch: 027/200 | Train MSE: 0.02895\n",
      "Epoch: 028/200 | Batch 000/178 | Cost: 0.0291\n",
      "Epoch: 028/200 | Train MSE: 0.02895\n",
      "Epoch: 029/200 | Batch 000/178 | Cost: 0.0291\n",
      "Epoch: 029/200 | Train MSE: 0.02890\n",
      "Epoch: 030/200 | Batch 000/178 | Cost: 0.0283\n",
      "Epoch: 030/200 | Train MSE: 0.02889\n",
      "Epoch: 031/200 | Batch 000/178 | Cost: 0.0289\n",
      "Epoch: 031/200 | Train MSE: 0.02894\n",
      "Epoch: 032/200 | Batch 000/178 | Cost: 0.0291\n",
      "Epoch: 032/200 | Train MSE: 0.02885\n",
      "Epoch: 033/200 | Batch 000/178 | Cost: 0.0286\n",
      "Epoch: 033/200 | Train MSE: 0.02883\n",
      "Epoch: 034/200 | Batch 000/178 | Cost: 0.0288\n",
      "Epoch: 034/200 | Train MSE: 0.02879\n",
      "Epoch: 035/200 | Batch 000/178 | Cost: 0.0284\n",
      "Epoch: 035/200 | Train MSE: 0.02877\n",
      "Epoch: 036/200 | Batch 000/178 | Cost: 0.0289\n",
      "Epoch: 036/200 | Train MSE: 0.02874\n",
      "Epoch: 037/200 | Batch 000/178 | Cost: 0.0286\n",
      "Epoch: 037/200 | Train MSE: 0.02875\n",
      "Epoch: 038/200 | Batch 000/178 | Cost: 0.0288\n",
      "Epoch: 038/200 | Train MSE: 0.02868\n",
      "Epoch: 039/200 | Batch 000/178 | Cost: 0.0288\n",
      "Epoch: 039/200 | Train MSE: 0.02872\n",
      "Epoch: 040/200 | Batch 000/178 | Cost: 0.0287\n",
      "Epoch: 040/200 | Train MSE: 0.02865\n",
      "Epoch: 041/200 | Batch 000/178 | Cost: 0.0285\n",
      "Epoch: 041/200 | Train MSE: 0.02863\n",
      "Epoch: 042/200 | Batch 000/178 | Cost: 0.0287\n",
      "Epoch: 042/200 | Train MSE: 0.02856\n",
      "Epoch: 043/200 | Batch 000/178 | Cost: 0.0285\n",
      "Epoch: 043/200 | Train MSE: 0.02852\n",
      "Epoch: 044/200 | Batch 000/178 | Cost: 0.0286\n",
      "Epoch: 044/200 | Train MSE: 0.02851\n",
      "Epoch: 045/200 | Batch 000/178 | Cost: 0.0287\n",
      "Epoch: 045/200 | Train MSE: 0.02849\n",
      "Epoch: 046/200 | Batch 000/178 | Cost: 0.0287\n",
      "Epoch: 046/200 | Train MSE: 0.02842\n",
      "Epoch: 047/200 | Batch 000/178 | Cost: 0.0288\n",
      "Epoch: 047/200 | Train MSE: 0.02846\n",
      "Epoch: 048/200 | Batch 000/178 | Cost: 0.0280\n",
      "Epoch: 048/200 | Train MSE: 0.02833\n",
      "Epoch: 049/200 | Batch 000/178 | Cost: 0.0280\n",
      "Epoch: 049/200 | Train MSE: 0.02830\n",
      "Epoch: 050/200 | Batch 000/178 | Cost: 0.0281\n",
      "Epoch: 050/200 | Train MSE: 0.02828\n",
      "Epoch: 051/200 | Batch 000/178 | Cost: 0.0280\n",
      "Epoch: 051/200 | Train MSE: 0.02821\n",
      "Epoch: 052/200 | Batch 000/178 | Cost: 0.0279\n",
      "Epoch: 052/200 | Train MSE: 0.02829\n",
      "Epoch: 053/200 | Batch 000/178 | Cost: 0.0273\n",
      "Epoch: 053/200 | Train MSE: 0.02822\n",
      "Epoch: 054/200 | Batch 000/178 | Cost: 0.0278\n",
      "Epoch: 054/200 | Train MSE: 0.02816\n",
      "Epoch: 055/200 | Batch 000/178 | Cost: 0.0283\n",
      "Epoch: 055/200 | Train MSE: 0.02820\n",
      "Epoch: 056/200 | Batch 000/178 | Cost: 0.0270\n",
      "Epoch: 056/200 | Train MSE: 0.02805\n",
      "Epoch: 057/200 | Batch 000/178 | Cost: 0.0285\n",
      "Epoch: 057/200 | Train MSE: 0.02810\n",
      "Epoch: 058/200 | Batch 000/178 | Cost: 0.0286\n",
      "Epoch: 058/200 | Train MSE: 0.02804\n",
      "Epoch: 059/200 | Batch 000/178 | Cost: 0.0284\n",
      "Epoch: 059/200 | Train MSE: 0.02816\n",
      "Epoch: 060/200 | Batch 000/178 | Cost: 0.0286\n",
      "Epoch: 060/200 | Train MSE: 0.02901\n",
      "Epoch: 061/200 | Batch 000/178 | Cost: 0.0281\n",
      "Epoch: 061/200 | Train MSE: 0.02780\n",
      "Epoch: 062/200 | Batch 000/178 | Cost: 0.0273\n",
      "Epoch: 062/200 | Train MSE: 0.02769\n",
      "Epoch: 063/200 | Batch 000/178 | Cost: 0.0270\n",
      "Epoch: 063/200 | Train MSE: 0.02760\n",
      "Epoch: 064/200 | Batch 000/178 | Cost: 0.0274\n",
      "Epoch: 064/200 | Train MSE: 0.02759\n",
      "Epoch: 065/200 | Batch 000/178 | Cost: 0.0279\n",
      "Epoch: 065/200 | Train MSE: 0.02769\n",
      "Epoch: 066/200 | Batch 000/178 | Cost: 0.0275\n",
      "Epoch: 066/200 | Train MSE: 0.02810\n",
      "Epoch: 067/200 | Batch 000/178 | Cost: 0.0292\n",
      "Epoch: 067/200 | Train MSE: 0.02803\n",
      "Epoch: 068/200 | Batch 000/178 | Cost: 0.0280\n",
      "Epoch: 068/200 | Train MSE: 0.02801\n",
      "Epoch: 069/200 | Batch 000/178 | Cost: 0.0276\n",
      "Epoch: 069/200 | Train MSE: 0.02774\n",
      "Epoch: 070/200 | Batch 000/178 | Cost: 0.0275\n",
      "Epoch: 070/200 | Train MSE: 0.02725\n",
      "Epoch: 071/200 | Batch 000/178 | Cost: 0.0262\n",
      "Epoch: 071/200 | Train MSE: 0.02724\n",
      "Epoch: 072/200 | Batch 000/178 | Cost: 0.0277\n",
      "Epoch: 072/200 | Train MSE: 0.02735\n",
      "Epoch: 073/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 073/200 | Train MSE: 0.02708\n",
      "Epoch: 074/200 | Batch 000/178 | Cost: 0.0276\n",
      "Epoch: 074/200 | Train MSE: 0.02712\n",
      "Epoch: 075/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 075/200 | Train MSE: 0.02706\n",
      "Epoch: 076/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 076/200 | Train MSE: 0.02749\n",
      "Epoch: 077/200 | Batch 000/178 | Cost: 0.0264\n",
      "Epoch: 077/200 | Train MSE: 0.02709\n",
      "Epoch: 078/200 | Batch 000/178 | Cost: 0.0277\n",
      "Epoch: 078/200 | Train MSE: 0.02708\n",
      "Epoch: 079/200 | Batch 000/178 | Cost: 0.0271\n",
      "Epoch: 079/200 | Train MSE: 0.02697\n",
      "Epoch: 080/200 | Batch 000/178 | Cost: 0.0284\n",
      "Epoch: 080/200 | Train MSE: 0.02689\n",
      "Epoch: 081/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 081/200 | Train MSE: 0.02658\n",
      "Epoch: 082/200 | Batch 000/178 | Cost: 0.0270\n",
      "Epoch: 082/200 | Train MSE: 0.02672\n",
      "Epoch: 083/200 | Batch 000/178 | Cost: 0.0268\n",
      "Epoch: 083/200 | Train MSE: 0.02664\n",
      "Epoch: 084/200 | Batch 000/178 | Cost: 0.0250\n",
      "Epoch: 084/200 | Train MSE: 0.02678\n",
      "Epoch: 085/200 | Batch 000/178 | Cost: 0.0260\n",
      "Epoch: 085/200 | Train MSE: 0.02685\n",
      "Epoch: 086/200 | Batch 000/178 | Cost: 0.0272\n",
      "Epoch: 086/200 | Train MSE: 0.02657\n",
      "Epoch: 087/200 | Batch 000/178 | Cost: 0.0253\n",
      "Epoch: 087/200 | Train MSE: 0.02701\n",
      "Epoch: 088/200 | Batch 000/178 | Cost: 0.0279\n",
      "Epoch: 088/200 | Train MSE: 0.02657\n",
      "Epoch: 089/200 | Batch 000/178 | Cost: 0.0284\n",
      "Epoch: 089/200 | Train MSE: 0.02629\n",
      "Epoch: 090/200 | Batch 000/178 | Cost: 0.0258\n",
      "Epoch: 090/200 | Train MSE: 0.02632\n",
      "Epoch: 091/200 | Batch 000/178 | Cost: 0.0248\n",
      "Epoch: 091/200 | Train MSE: 0.02698\n",
      "Epoch: 092/200 | Batch 000/178 | Cost: 0.0272\n",
      "Epoch: 092/200 | Train MSE: 0.02601\n",
      "Epoch: 093/200 | Batch 000/178 | Cost: 0.0262\n",
      "Epoch: 093/200 | Train MSE: 0.02635\n",
      "Epoch: 094/200 | Batch 000/178 | Cost: 0.0266\n",
      "Epoch: 094/200 | Train MSE: 0.02653\n",
      "Epoch: 095/200 | Batch 000/178 | Cost: 0.0276\n",
      "Epoch: 095/200 | Train MSE: 0.02742\n",
      "Epoch: 096/200 | Batch 000/178 | Cost: 0.0276\n",
      "Epoch: 096/200 | Train MSE: 0.02716\n",
      "Epoch: 097/200 | Batch 000/178 | Cost: 0.0265\n",
      "Epoch: 097/200 | Train MSE: 0.02608\n",
      "Epoch: 098/200 | Batch 000/178 | Cost: 0.0272\n",
      "Epoch: 098/200 | Train MSE: 0.02593\n",
      "Epoch: 099/200 | Batch 000/178 | Cost: 0.0250\n",
      "Epoch: 099/200 | Train MSE: 0.02628\n",
      "Epoch: 100/200 | Batch 000/178 | Cost: 0.0262\n",
      "Epoch: 100/200 | Train MSE: 0.02614\n",
      "Epoch: 101/200 | Batch 000/178 | Cost: 0.0268\n",
      "Epoch: 101/200 | Train MSE: 0.02606\n",
      "Epoch: 102/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 102/200 | Train MSE: 0.02595\n",
      "Epoch: 103/200 | Batch 000/178 | Cost: 0.0265\n",
      "Epoch: 103/200 | Train MSE: 0.02545\n",
      "Epoch: 104/200 | Batch 000/178 | Cost: 0.0264\n",
      "Epoch: 104/200 | Train MSE: 0.02572\n",
      "Epoch: 105/200 | Batch 000/178 | Cost: 0.0248\n",
      "Epoch: 105/200 | Train MSE: 0.02609\n",
      "Epoch: 106/200 | Batch 000/178 | Cost: 0.0257\n",
      "Epoch: 106/200 | Train MSE: 0.02858\n",
      "Epoch: 107/200 | Batch 000/178 | Cost: 0.0295\n",
      "Epoch: 107/200 | Train MSE: 0.02579\n",
      "Epoch: 108/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 108/200 | Train MSE: 0.02541\n",
      "Epoch: 109/200 | Batch 000/178 | Cost: 0.0246\n",
      "Epoch: 109/200 | Train MSE: 0.02571\n",
      "Epoch: 110/200 | Batch 000/178 | Cost: 0.0243\n",
      "Epoch: 110/200 | Train MSE: 0.02543\n",
      "Epoch: 111/200 | Batch 000/178 | Cost: 0.0244\n",
      "Epoch: 111/200 | Train MSE: 0.02614\n",
      "Epoch: 112/200 | Batch 000/178 | Cost: 0.0271\n",
      "Epoch: 112/200 | Train MSE: 0.02588\n",
      "Epoch: 113/200 | Batch 000/178 | Cost: 0.0280\n",
      "Epoch: 113/200 | Train MSE: 0.02547\n",
      "Epoch: 114/200 | Batch 000/178 | Cost: 0.0262\n",
      "Epoch: 114/200 | Train MSE: 0.02522\n",
      "Epoch: 115/200 | Batch 000/178 | Cost: 0.0252\n",
      "Epoch: 115/200 | Train MSE: 0.02537\n",
      "Epoch: 116/200 | Batch 000/178 | Cost: 0.0263\n",
      "Epoch: 116/200 | Train MSE: 0.02548\n",
      "Epoch: 117/200 | Batch 000/178 | Cost: 0.0264\n",
      "Epoch: 117/200 | Train MSE: 0.02665\n",
      "Epoch: 118/200 | Batch 000/178 | Cost: 0.0277\n",
      "Epoch: 118/200 | Train MSE: 0.02579\n",
      "Epoch: 119/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 119/200 | Train MSE: 0.02512\n",
      "Epoch: 120/200 | Batch 000/178 | Cost: 0.0261\n",
      "Epoch: 120/200 | Train MSE: 0.02487\n",
      "Epoch: 121/200 | Batch 000/178 | Cost: 0.0250\n",
      "Epoch: 121/200 | Train MSE: 0.02666\n",
      "Epoch: 122/200 | Batch 000/178 | Cost: 0.0271\n",
      "Epoch: 122/200 | Train MSE: 0.02508\n",
      "Epoch: 123/200 | Batch 000/178 | Cost: 0.0248\n",
      "Epoch: 123/200 | Train MSE: 0.02472\n",
      "Epoch: 124/200 | Batch 000/178 | Cost: 0.0243\n",
      "Epoch: 124/200 | Train MSE: 0.02544\n",
      "Epoch: 125/200 | Batch 000/178 | Cost: 0.0259\n",
      "Epoch: 125/200 | Train MSE: 0.02663\n",
      "Epoch: 126/200 | Batch 000/178 | Cost: 0.0259\n",
      "Epoch: 126/200 | Train MSE: 0.02641\n",
      "Epoch: 127/200 | Batch 000/178 | Cost: 0.0250\n",
      "Epoch: 127/200 | Train MSE: 0.02647\n",
      "Epoch: 128/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 128/200 | Train MSE: 0.02755\n",
      "Epoch: 129/200 | Batch 000/178 | Cost: 0.0287\n",
      "Epoch: 129/200 | Train MSE: 0.02499\n",
      "Epoch: 130/200 | Batch 000/178 | Cost: 0.0264\n",
      "Epoch: 130/200 | Train MSE: 0.02479\n",
      "Epoch: 131/200 | Batch 000/178 | Cost: 0.0235\n",
      "Epoch: 131/200 | Train MSE: 0.02465\n",
      "Epoch: 132/200 | Batch 000/178 | Cost: 0.0256\n",
      "Epoch: 132/200 | Train MSE: 0.02563\n",
      "Epoch: 133/200 | Batch 000/178 | Cost: 0.0273\n",
      "Epoch: 133/200 | Train MSE: 0.02457\n",
      "Epoch: 134/200 | Batch 000/178 | Cost: 0.0239\n",
      "Epoch: 134/200 | Train MSE: 0.02476\n",
      "Epoch: 135/200 | Batch 000/178 | Cost: 0.0254\n",
      "Epoch: 135/200 | Train MSE: 0.02511\n",
      "Epoch: 136/200 | Batch 000/178 | Cost: 0.0234\n",
      "Epoch: 136/200 | Train MSE: 0.02456\n",
      "Epoch: 137/200 | Batch 000/178 | Cost: 0.0254\n",
      "Epoch: 137/200 | Train MSE: 0.02486\n",
      "Epoch: 138/200 | Batch 000/178 | Cost: 0.0250\n",
      "Epoch: 138/200 | Train MSE: 0.02481\n",
      "Epoch: 139/200 | Batch 000/178 | Cost: 0.0266\n",
      "Epoch: 139/200 | Train MSE: 0.02514\n",
      "Epoch: 140/200 | Batch 000/178 | Cost: 0.0262\n",
      "Epoch: 140/200 | Train MSE: 0.02459\n",
      "Epoch: 141/200 | Batch 000/178 | Cost: 0.0249\n",
      "Epoch: 141/200 | Train MSE: 0.02467\n",
      "Epoch: 142/200 | Batch 000/178 | Cost: 0.0247\n",
      "Epoch: 142/200 | Train MSE: 0.02466\n",
      "Epoch: 143/200 | Batch 000/178 | Cost: 0.0230\n",
      "Epoch: 143/200 | Train MSE: 0.02484\n",
      "Epoch: 144/200 | Batch 000/178 | Cost: 0.0242\n",
      "Epoch: 144/200 | Train MSE: 0.02398\n",
      "Epoch: 145/200 | Batch 000/178 | Cost: 0.0248\n",
      "Epoch: 145/200 | Train MSE: 0.02436\n",
      "Epoch: 146/200 | Batch 000/178 | Cost: 0.0253\n",
      "Epoch: 146/200 | Train MSE: 0.02571\n",
      "Epoch: 147/200 | Batch 000/178 | Cost: 0.0239\n",
      "Epoch: 147/200 | Train MSE: 0.02401\n",
      "Epoch: 148/200 | Batch 000/178 | Cost: 0.0221\n",
      "Epoch: 148/200 | Train MSE: 0.02393\n",
      "Epoch: 149/200 | Batch 000/178 | Cost: 0.0243\n",
      "Epoch: 149/200 | Train MSE: 0.02627\n",
      "Epoch: 150/200 | Batch 000/178 | Cost: 0.0239\n",
      "Epoch: 150/200 | Train MSE: 0.02417\n",
      "Epoch: 151/200 | Batch 000/178 | Cost: 0.0252\n",
      "Epoch: 151/200 | Train MSE: 0.02441\n",
      "Epoch: 152/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 152/200 | Train MSE: 0.02476\n",
      "Epoch: 153/200 | Batch 000/178 | Cost: 0.0266\n",
      "Epoch: 153/200 | Train MSE: 0.02374\n",
      "Epoch: 154/200 | Batch 000/178 | Cost: 0.0239\n",
      "Epoch: 154/200 | Train MSE: 0.02425\n",
      "Epoch: 155/200 | Batch 000/178 | Cost: 0.0225\n",
      "Epoch: 155/200 | Train MSE: 0.02517\n",
      "Epoch: 156/200 | Batch 000/178 | Cost: 0.0273\n",
      "Epoch: 156/200 | Train MSE: 0.02400\n",
      "Epoch: 157/200 | Batch 000/178 | Cost: 0.0241\n",
      "Epoch: 157/200 | Train MSE: 0.02420\n",
      "Epoch: 158/200 | Batch 000/178 | Cost: 0.0226\n",
      "Epoch: 158/200 | Train MSE: 0.02406\n",
      "Epoch: 159/200 | Batch 000/178 | Cost: 0.0242\n",
      "Epoch: 159/200 | Train MSE: 0.02430\n",
      "Epoch: 160/200 | Batch 000/178 | Cost: 0.0254\n",
      "Epoch: 160/200 | Train MSE: 0.02531\n",
      "Epoch: 161/200 | Batch 000/178 | Cost: 0.0237\n",
      "Epoch: 161/200 | Train MSE: 0.02393\n",
      "Epoch: 162/200 | Batch 000/178 | Cost: 0.0233\n",
      "Epoch: 162/200 | Train MSE: 0.02504\n",
      "Epoch: 163/200 | Batch 000/178 | Cost: 0.0273\n",
      "Epoch: 163/200 | Train MSE: 0.02418\n",
      "Epoch: 164/200 | Batch 000/178 | Cost: 0.0253\n",
      "Epoch: 164/200 | Train MSE: 0.02539\n",
      "Epoch: 165/200 | Batch 000/178 | Cost: 0.0256\n",
      "Epoch: 165/200 | Train MSE: 0.02502\n",
      "Epoch: 166/200 | Batch 000/178 | Cost: 0.0252\n",
      "Epoch: 166/200 | Train MSE: 0.02372\n",
      "Epoch: 167/200 | Batch 000/178 | Cost: 0.0215\n",
      "Epoch: 167/200 | Train MSE: 0.02320\n",
      "Epoch: 168/200 | Batch 000/178 | Cost: 0.0228\n",
      "Epoch: 168/200 | Train MSE: 0.02915\n",
      "Epoch: 169/200 | Batch 000/178 | Cost: 0.0284\n",
      "Epoch: 169/200 | Train MSE: 0.02377\n",
      "Epoch: 170/200 | Batch 000/178 | Cost: 0.0250\n",
      "Epoch: 170/200 | Train MSE: 0.02797\n",
      "Epoch: 171/200 | Batch 000/178 | Cost: 0.0288\n",
      "Epoch: 171/200 | Train MSE: 0.02533\n",
      "Epoch: 172/200 | Batch 000/178 | Cost: 0.0244\n",
      "Epoch: 172/200 | Train MSE: 0.02414\n",
      "Epoch: 173/200 | Batch 000/178 | Cost: 0.0236\n",
      "Epoch: 173/200 | Train MSE: 0.02395\n",
      "Epoch: 174/200 | Batch 000/178 | Cost: 0.0235\n",
      "Epoch: 174/200 | Train MSE: 0.02590\n",
      "Epoch: 175/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 175/200 | Train MSE: 0.02363\n",
      "Epoch: 176/200 | Batch 000/178 | Cost: 0.0246\n",
      "Epoch: 176/200 | Train MSE: 0.02404\n",
      "Epoch: 177/200 | Batch 000/178 | Cost: 0.0250\n",
      "Epoch: 177/200 | Train MSE: 0.02318\n",
      "Epoch: 178/200 | Batch 000/178 | Cost: 0.0219\n",
      "Epoch: 178/200 | Train MSE: 0.02320\n",
      "Epoch: 179/200 | Batch 000/178 | Cost: 0.0257\n",
      "Epoch: 179/200 | Train MSE: 0.02362\n",
      "Epoch: 180/200 | Batch 000/178 | Cost: 0.0249\n",
      "Epoch: 180/200 | Train MSE: 0.02640\n",
      "Epoch: 181/200 | Batch 000/178 | Cost: 0.0257\n",
      "Epoch: 181/200 | Train MSE: 0.02350\n",
      "Epoch: 182/200 | Batch 000/178 | Cost: 0.0238\n",
      "Epoch: 182/200 | Train MSE: 0.02393\n",
      "Epoch: 183/200 | Batch 000/178 | Cost: 0.0252\n",
      "Epoch: 183/200 | Train MSE: 0.02743\n",
      "Epoch: 184/200 | Batch 000/178 | Cost: 0.0266\n",
      "Epoch: 184/200 | Train MSE: 0.02704\n",
      "Epoch: 185/200 | Batch 000/178 | Cost: 0.0261\n",
      "Epoch: 185/200 | Train MSE: 0.02397\n",
      "Epoch: 186/200 | Batch 000/178 | Cost: 0.0233\n",
      "Epoch: 186/200 | Train MSE: 0.02295\n",
      "Epoch: 187/200 | Batch 000/178 | Cost: 0.0240\n",
      "Epoch: 187/200 | Train MSE: 0.02368\n",
      "Epoch: 188/200 | Batch 000/178 | Cost: 0.0239\n",
      "Epoch: 188/200 | Train MSE: 0.02333\n",
      "Epoch: 189/200 | Batch 000/178 | Cost: 0.0229\n",
      "Epoch: 189/200 | Train MSE: 0.02267\n",
      "Epoch: 190/200 | Batch 000/178 | Cost: 0.0232\n",
      "Epoch: 190/200 | Train MSE: 0.02380\n",
      "Epoch: 191/200 | Batch 000/178 | Cost: 0.0245\n",
      "Epoch: 191/200 | Train MSE: 0.02582\n",
      "Epoch: 192/200 | Batch 000/178 | Cost: 0.0267\n",
      "Epoch: 192/200 | Train MSE: 0.02523\n",
      "Epoch: 193/200 | Batch 000/178 | Cost: 0.0225\n",
      "Epoch: 193/200 | Train MSE: 0.02334\n",
      "Epoch: 194/200 | Batch 000/178 | Cost: 0.0234\n",
      "Epoch: 194/200 | Train MSE: 0.02333\n",
      "Epoch: 195/200 | Batch 000/178 | Cost: 0.0238\n",
      "Epoch: 195/200 | Train MSE: 0.02283\n",
      "Epoch: 196/200 | Batch 000/178 | Cost: 0.0238\n",
      "Epoch: 196/200 | Train MSE: 0.02368\n",
      "Epoch: 197/200 | Batch 000/178 | Cost: 0.0213\n",
      "Epoch: 197/200 | Train MSE: 0.02366\n",
      "Epoch: 198/200 | Batch 000/178 | Cost: 0.0241\n",
      "Epoch: 198/200 | Train MSE: 0.02364\n",
      "Epoch: 199/200 | Batch 000/178 | Cost: 0.0241\n",
      "Epoch: 199/200 | Train MSE: 0.02371\n",
      "Epoch: 200/200 | Batch 000/178 | Cost: 0.0248\n",
      "Epoch: 200/200 | Train MSE: 0.02257\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(23)\n",
    "model=MLPS(num_features=32*32*3,\n",
    "           hidden=512,num_classes=33)\n",
    "minibatch_cost2,epoch_cost2=\\\n",
    "model_train(model,train_loader2,\n",
    "            num_epochs=200,learning_rate=.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 44.52\n",
      "Test Accuracy: 42.00\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy: %.2f'%model_acc(model,train_loader2))\n",
    "print('Test Accuracy: %.2f'%model_acc(model,test_loader2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
